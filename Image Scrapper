from bs4 import BeautifulSoup
import requests
import urllib.request
import pandas as pd

final static data_path = '/content/drive/MyDrive/Ralph_Lauren_Retail_Feed.csv'

def scrap_images(data_path)
df = pd.read_csv(data_path)

for i in range(len(df)):
  html_page = requests.get(df['url'][i])
  soup = BeautifulSoup(html_page.content, 'html.parser')
  
  images = [img.get('data-img') for img in soup.findAll('img') if img]

  # setting filename and image URL
  prod_type = df['product_type'][i]
  sku = df['sku'][i]
  filename = 'Images/'+prod_type+'_'+sku+'.jpg'
  if images:
    image_url = images[0]

  
  # calling urlretrieve function to get resource
  response = requests.get(image_url)

  file = open(filename, "wb")
  file.write(response.content)
  file.close()

if __name__ == '__main__':
  scrap_images(data_path)
